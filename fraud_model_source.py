# -*- coding: utf-8 -*-
"""fraud_model_source.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CxW9RUybPv31Pg1zkE9KFgHUXktsCAhl
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df_train = pd.read_csv('fraudTrain.csv')
df_test = pd.read_csv('fraudTest.csv')

df_train.head()

df_train.describe()

df_test.head()

df_test.describe()

df_train['fraud_label'] = df_train['is_fraud'].apply(lambda x: 1 if x >= 0.5 else 0)
class_distribution = df_train['fraud_label'].value_counts(normalize=True) * 100

class_distribution

df_train.info()

plt.figure(figsize=(10, 6))
sns.histplot(data=df_train, x='amt', hue='fraud_label', bins=50, kde=True, stat="density", common_norm=False)
plt.xlabel("Transaction Amount")
plt.ylabel("Density")
plt.title("Distribution of Transaction Amounts for Fraud vs Non-Fraud")
plt.legend(title="Fraud", labels=["Fraud", "Non-Fraud"])
plt.show()

df_train['trans_date_trans_time'] = pd.to_datetime(df_train['trans_date_trans_time'])
df_train['transaction_hour'] = df_train['trans_date_trans_time'].dt.hour

plt.figure(figsize=(10, 6))
sns.countplot(data=df_train, x='transaction_hour', hue='fraud_label')
plt.xlabel("Hour of Day")
plt.ylabel("Transaction Count")
plt.title("Transactions by Hour of Day for Fraud vs Non-Fraud")
plt.legend(title="Fraud", labels=["Non-Fraud", "Fraud"])
plt.show()

unnecessary_columns = [
    'Unnamed: 0', 'first', 'last', 'street', 'city', 'state', 'zip', 'dob', 'trans_num', 'job', 'is_fraud', 'fraud_label', 'transaction_date',
    'trans_date_trans_time'
]

target = df_train['fraud_label']

target

df_train['trans_date_trans_time'] = pd.to_datetime(df_train['trans_date_trans_time'])
df_train['transaction_hour'] = df_train['trans_date_trans_time'].dt.hour
df_train['transaction_day_of_week'] = df_train['trans_date_trans_time'].dt.dayofweek

df_train['off_hours'] = df_train['trans_date_trans_time'].dt.hour.apply(lambda x: 1 if x >= 22 or x < 6 else 0)

df_train['age'] = df_train['dob'].apply(lambda x: 2024 - pd.to_datetime(x).year)

features = df_train.drop(unnecessary_columns, axis=1)

features.info()

features = features.dropna()

for col in ["merchant", "category"]:
    freq_encoding = features[col].value_counts().to_dict()
    features[col] = features[col].map(freq_encoding)

features = pd.get_dummies(features, columns=["gender"])

features

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X_train, X_val, y_train, y_val = train_test_split(features, target, test_size=0.2, random_state=42, stratify=target)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)

X_train[0]

X_train[1]

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pickle

import xgboost as xgb
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier

lr_model = LogisticRegression(class_weight='balanced', random_state=42)

lr_model.fit(X_train, y_train)

lr_predictions = lr_model.predict(X_val)

lr_predictions

lr_accuracy = accuracy_score(y_val, lr_predictions)

lr_accuracy

print(f"\nClassification Report:\n{classification_report(y_val, lr_predictions)}")
print("*-----------------------------------------------------*")

from sklearn.metrics import roc_auc_score, f1_score

def evaluate_and_save_model(model, X_train, X_val, y_train, y_val, filename):
    model.fit(X_train, y_train)

    y_pred = model.predict(X_val)
    y_pred_proba = model.predict_proba(X_val)[:, 1]

    accuracy = accuracy_score(y_val, y_pred)
    print(f"{model.__class__.__name__} Accuracy: {accuracy:.4f}")

    auc = roc_auc_score(y_val, y_pred_proba) if hasattr(model, "predict_proba") else "N/A"
    f1 = f1_score(y_val, y_pred)
    print(f"\nClassification Report:\n{classification_report(y_val, y_pred)}")
    print("Confusion Matrix:")
    print(confusion_matrix(y_val, y_pred))
    print(f"AUC-ROC Score: {auc:.4f}" if auc != "N/A" else "AUC-ROC Score: Not Available")
    print(f"F1 Score: {f1:.4f}")

    with open(filename, 'wb') as file:
        pickle.dump(model, file)
    print(f"Model saved as {filename}")

    print("*-----------------------------------------------------*")

xgb_model = xgb.XGBClassifier(scale_pos_weight=len(y_train) / sum(y_train), random_state=42)
evaluate_and_save_model(xgb_model, X_train, X_val, y_train, y_val, 'xgb_model.pkl')

dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=42)
evaluate_and_save_model(dt_model, X_train, X_val, y_train, y_val, 'dt_model.pkl')

rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)
evaluate_and_save_model(rf_model, X_train, X_val, y_train, y_val, 'rf_model.pkl')

nb_model = GaussianNB()
evaluate_and_save_model(nb_model, X_train, X_val, y_train, y_val, 'nb_model.pkl')

knn_model = KNeighborsClassifier(n_neighbors=5)
evaluate_and_save_model(knn_model, X_train, X_val, y_train, y_val, 'knn_model.pkl')

svm_model = SVC(probability=True, random_state=42)
evaluate_and_save_model(svm_model, X_train, X_val, y_train, y_val, 'svm_model.pkl')

feature_importances = xgb_model.feature_importances_
feature_names = features.columns

feature_importances

feature_names

feature_importances_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': feature_importances
})

feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
plt.barh(feature_importances_df['Feature'].head(10), feature_importances_df['Importance'].head(10))
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Top 10 Feature Importances')
plt.gca().invert_yaxis()
plt.show()

features['AgeGroup'] = pd.cut(df_train['age'], bins=[0, 30, 45, 60, 100], labels=['Young', 'Adult', 'Middle-Aged', 'Senior'])

features

features = pd.get_dummies(features, drop_first=True)

features

X_train, X_val, y_train, y_val = train_test_split(features, target, test_size=0.2, random_state=42)

xgboost_model = xgb.XGBClassifier(scale_pos_weight=len(y_train) / sum(y_train), random_state=42)
evaluate_and_save_model(xgboost_model, X_train, X_val, y_train, y_val, 'xgboost_feature_engineering_model.pkl')

"""SINCE FEATURE ENGINEERED MODEL UNDER-PERFORMED COMPARATIVELY TO ORIGINAL XGBOOST, WE WILL PROCEED WITH THE PREVIOUS VERSION."""

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)

x_resampled, y_resampled = smote.fit_resample(X_train, y_train)

evaluate_and_save_model(xgboost_model, x_resampled, X_val, y_resampled, y_val, 'xgboost_smote.pkl')

"""SO SMOTE-ENHANCED MODEL INCREASED RECALL SLIGHTLY AT THE EXPENSE OF FALSE POSITIVES, ORIGINAL XGBOOST STILL PERFORMS THE BEST OVERALL."""

from sklearn.ensemble import VotingClassifier

voting_clf = VotingClassifier(estimators=[
    ('xgboost', xgb.XGBClassifier(scale_pos_weight=len(y_train) / sum(y_train), random_state=42)),
    ('dt', DecisionTreeClassifier(class_weight='balanced', random_state=42)),
    ('rf', RandomForestClassifier(class_weight='balanced', random_state=42))
], voting='soft')

evaluate_and_save_model(voting_clf, x_resampled, X_val, y_resampled, y_val, 'voting_clf.pkl')

"""XGBOOST (OG) STILL OUTPERFORMS, HENCE FINALIZED"""

